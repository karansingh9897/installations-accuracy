from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from gradio_client import Client, handle_file
import os
import time
import json

# Set your Hugging Face token
hf_token = "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"  # Replace with your actual token

# Initialize client
client = Client("Qwen/Qwen2.5-VL-32B-Instruct", hf_token=hf_token)

app = FastAPI()

@app.post("/analyze/")
async def analyze_image(file: UploadFile = File(...)):
    try:
        # Save the uploaded file temporarily
        image_path = f"/tmp/{file.filename}"
        with open(image_path, "wb") as f:
            f.write(await file.read())

        # Step 1: Upload the image
        history_after_image = client.predict(
            history=[],
            file=handle_file(image_path),
            api_name="/add_file"
        )

        # Add delay to ensure processing
        time.sleep(3)

        # Define your prompt
        prompt = ''' à¤†à¤ªà¤•à¥‹ à¤à¤• à¤¹à¥€ à¤µà¤¾à¤¹à¤¨ à¤•à¥€ à¤•à¤ˆ à¤‡à¤®à¥‡à¤œ à¤¦à¥€ à¤—à¤ˆ à¤¹à¥ˆà¤‚, à¤œà¥‹ à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¤° à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤•à¤¿à¤ à¤—à¤ GPS à¤¡à¤¿à¤µà¤¾à¤‡à¤¸ à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¥‡à¤¶à¤¨ à¤•à¥‹ à¤¦à¤°à¥à¤¶à¤¾à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤ à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¤° à¤¨à¥‡ à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¥‡à¤¶à¤¨ à¤ªà¥‚à¤°à¤¾ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤¬à¤¾à¤¦ à¤¡à¥‡à¤Ÿà¤¾ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¤¿à¤¯à¤¾ à¤¹à¥ˆ, à¤”à¤° à¤…à¤¬ à¤†à¤ªà¤•à¥‹ à¤‡à¤¸à¤•à¥€ à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ à¤•à¤°à¤¨à¥€ à¤¹à¥ˆà¥¤

        à¤†à¤ªà¤•à¤¾ à¤•à¤¾à¤°à¥à¤¯ à¤¨à¤¿à¤®à¥à¤¨à¤²à¤¿à¤–à¤¿à¤¤ à¤¹à¥ˆ:

        âœ… à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¥‡à¤¶à¤¨ à¤¸à¥à¤§à¤¾à¤° à¤¬à¤¿à¤‚à¤¦à¥ à¤•à¥€ à¤¸à¥‚à¤šà¥€ à¤¬à¤¨à¤¾à¤à¤‚ à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¥à¤¯à¥‡à¤• à¤¬à¤¿à¤‚à¤¦à¥ 5 à¤¶à¤¬à¥à¤¦à¥‹à¤‚ à¤¸à¥‡ à¤…à¤§à¤¿à¤• à¤¨ à¤¹à¥‹ à¤”à¤° à¤‰à¤¸à¤•à¥‡ à¤¬à¤¾à¤¦ â€œâž¡ Rating: X/10â€ à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤°à¥‡à¤Ÿà¤¿à¤‚à¤— à¤¹à¥‹à¥¤

        à¤¹à¤° à¤¬à¤¿à¤‚à¤¦à¥ à¤à¤• à¤¨à¤‚à¤¬à¤° à¤¸à¥‡ à¤¦à¤°à¥à¤¶à¤¾à¤à¤‚ (1ï¸âƒ£, 2ï¸âƒ£, 3ï¸âƒ£ â€¦)à¥¤
        à¤¬à¤¿à¤‚à¤¦à¥à¤“à¤‚ à¤œà¥ˆà¤¸à¥‡ â€œà¤¤à¤¾à¤° à¤¢à¤¿à¤²à¥‡ à¤¹à¥ˆà¤‚ â€“ à¤…à¤šà¥à¤›à¥‡ à¤¸à¥‡ à¤¬à¤¾à¤‚à¤§à¥‹â€, â€œà¤¬à¤¹à¥à¤¤ à¤¸à¤¾à¤°à¥‡ à¤¤à¤¾à¤° à¤¬à¤¾à¤¹à¤° à¤¹à¥ˆà¤‚ â€“ à¤Ÿà¥‡à¤ª à¤¸à¥‡ à¤²à¤ªà¥‡à¤Ÿà¥‹â€ à¤†à¤¦à¤¿ à¤•à¥‹ à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚à¥¤
        à¤•à¥à¤² à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¥‡à¤¶à¤¨ à¤•à¥€ à¤°à¥‡à¤Ÿà¤¿à¤‚à¤— à¤¦à¥‡à¤‚, à¤‰à¤¦à¤¾à¤¹à¤°à¤£ à¤•à¥‡ à¤²à¤¿à¤: â€œðŸš€ à¤•à¥à¤² à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¥‡à¤¶à¤¨ à¤°à¥‡à¤Ÿà¤¿à¤‚à¤—: 3/10â€à¥¤
        à¤…à¤‚à¤¤ à¤®à¥‡à¤‚ à¤à¤• à¤›à¥‹à¤Ÿà¤¾ à¤ªà¥à¤°à¥‡à¤°à¤£à¤¾à¤¦à¤¾à¤¯à¤• à¤¨à¥‹à¤Ÿ à¤¦à¥‡à¤‚, à¤œà¥ˆà¤¸à¥‡:
        âž¡ à¤…à¤§à¤¿à¤• à¤°à¥à¤ªà¤¯à¥‡ à¤šà¤¾à¤¹à¤¿à¤? à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤²à¥‡à¤¶à¤¨ à¤¸à¥à¤§à¤¾à¤°à¥‹, à¤«à¤¿à¤° à¤…à¤§à¤¿à¤• à¤®à¤¿à¤²à¥‡à¤—à¤¾à¥¤
        '''

        # Step 2: Add the text prompt
        history_after_text = client.predict(
            text=prompt,
            api_name="/add_text"
        )

        # Add delay to ensure processing
        time.sleep(3)

        # Step 3: Get the model's response
        result = client.predict(
            _chatbot=history_after_text,
            api_name="/predict"
        )

        # Extract the final response
        if result and len(result) > 0:
            model_response = result[-1][1]
            return JSONResponse(content={"analysis": model_response})
        else:
            return JSONResponse(content={"error": "No response received from the model"}, status_code=500)

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

