from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import os
import time
import tempfile

# Initialize FastAPI app first
app = FastAPI(title="Vehicle Installation Analysis API", version="1.0.0")

# Set your Hugging Face token
hf_token = "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"  # Replace with your actual token

# Initialize Gradio client after app creation
client = None

@app.on_event("startup")
async def startup_event():
    global client
    try:
        from gradio_client import Client, handle_file
        client = Client("Qwen/Qwen2.5-VL-32B-Instruct", hf_token=hf_token)
        print("‚úÖ Gradio client initialized successfully")
    except Exception as e:
        print(f"‚ùå Error initializing Gradio client: {e}")
        client = None

@app.get("/")
async def root():
    return {"message": "Vehicle Installation Analysis API is running!"}

@app.get("/health")
async def health_check():
    return {
        "status": "healthy", 
        "client_status": "connected" if client else "disconnected"
    }

@app.post("/analyze/")
async def analyze_image(file: UploadFile = File(...)):
    if not client:
        return JSONResponse(
            content={"error": "Gradio client not initialized. Please check server logs."}, 
            status_code=500
        )
    
    try:
        from gradio_client import handle_file
        
        # Validate file type
        if not file.content_type.startswith('image/'):
            return JSONResponse(
                content={"error": "Please upload an image file"}, 
                status_code=400
            )
        
        # Create a temporary file to save the uploaded image
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{file.filename}") as temp_file:
            content = await file.read()
            temp_file.write(content)
            image_path = temp_file.name

        print(f"üìÅ Image saved to: {image_path}")

        # Step 1: Upload the image
        history_after_image = client.predict(
            history=[],
            file=handle_file(image_path),
            api_name="/add_file"
        )
        print("‚úÖ Image uploaded successfully")

        # Add delay to ensure processing
        time.sleep(3)

        # Define your prompt
        prompt = ''' ‡§Ü‡§™‡§ï‡•ã ‡§è‡§ï ‡§π‡•Ä ‡§µ‡§æ‡§π‡§® ‡§ï‡•Ä ‡§ï‡§à ‡§á‡§Æ‡•á‡§ú ‡§¶‡•Ä ‡§ó‡§à ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡§ø‡§è ‡§ó‡§è GPS ‡§°‡§ø‡§µ‡§æ‡§á‡§∏ ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§ï‡•ã ‡§¶‡§∞‡•ç‡§∂‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç‡•§ ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡§∞ ‡§®‡•á ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§°‡•á‡§ü‡§æ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§Ö‡§¨ ‡§Ü‡§™‡§ï‡•ã ‡§á‡§∏‡§ï‡•Ä ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡§®‡•Ä ‡§π‡•à‡•§

        ‡§Ü‡§™‡§ï‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§π‡•à:

        ‚úÖ ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§¨‡§ø‡§Ç‡§¶‡•Å ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§¨‡§®‡§æ‡§è‡§Ç ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§¨‡§ø‡§Ç‡§¶‡•Å 5 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§® ‡§π‡•ã ‡§î‡§∞ ‡§â‡§∏‡§ï‡•á ‡§¨‡§æ‡§¶ "‚û° Rating: X/10" ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§π‡•ã‡•§

        ‡§π‡§∞ ‡§¨‡§ø‡§Ç‡§¶‡•Å ‡§è‡§ï ‡§®‡§Ç‡§¨‡§∞ ‡§∏‡•á ‡§¶‡§∞‡•ç‡§∂‡§æ‡§è‡§Ç (1Ô∏è‚É£, 2Ô∏è‚É£, 3Ô∏è‚É£ ‚Ä¶)‡•§
        ‡§¨‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ú‡•à‡§∏‡•á "‡§§‡§æ‡§∞ ‡§¢‡§ø‡§≤‡•á ‡§π‡•à‡§Ç ‚Äì ‡§Ö‡§ö‡•ç‡§õ‡•á ‡§∏‡•á ‡§¨‡§æ‡§Ç‡§ß‡•ã", "‡§¨‡§π‡•Å‡§§ ‡§∏‡§æ‡§∞‡•á ‡§§‡§æ‡§∞ ‡§¨‡§æ‡§π‡§∞ ‡§π‡•à‡§Ç ‚Äì ‡§ü‡•á‡§™ ‡§∏‡•á ‡§≤‡§™‡•á‡§ü‡•ã" ‡§Ü‡§¶‡§ø ‡§ï‡•ã ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§
        ‡§ï‡•Å‡§≤ ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§ï‡•Ä ‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§¶‡•á‡§Ç, ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§ï‡•á ‡§§‡•å‡§∞ ‡§™‡§∞: "üöÄ ‡§ï‡•Å‡§≤ ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó: 3/10"‡•§
        ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ ‡§™‡•ç‡§∞‡•á‡§∞‡§£‡§æ‡§¶‡§æ‡§Ø‡§ï ‡§®‡•ã‡§ü ‡§¶‡•á‡§Ç, ‡§ú‡•à‡§∏‡•á:
        ‚û° ‡§Ö‡§ß‡§ø‡§ï ‡§∞‡•Å‡§™‡§Ø‡•á ‡§ö‡§æ‡§π‡§ø‡§è? ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ã, ‡§´‡§ø‡§∞ ‡§Ö‡§ß‡§ø‡§ï ‡§Æ‡§ø‡§≤‡•á‡§ó‡§æ‡•§
        '''

        # Step 2: Add the text prompt
        history_after_text = client.predict(
            text=prompt,
            api_name="/add_text"
        )
        print("‚úÖ Text prompt added successfully")

        # Add delay to ensure processing
        time.sleep(3)

        # Step 3: Get the model's response
        result = client.predict(
            _chatbot=history_after_text,
            api_name="/predict"
        )
        print("‚úÖ Model response generated")

        # Clean up temporary file
        os.unlink(image_path)

        # Extract the final response
        if result and len(result) > 0:
            model_response = result[-1][1]
            return JSONResponse(content={
                "status": "success",
                "analysis": model_response,
                "filename": file.filename,
                "file_size": len(content)
            })
        else:
            return JSONResponse(
                content={"error": "No response received from the model"}, 
                status_code=500
            )

    except Exception as e:
        # Clean up temporary file if it exists
        if 'image_path' in locals():
            try:
                os.unlink(image_path)
            except:
                pass
        
        print(f"‚ùå Error in analyze_image: {str(e)}")
        return JSONResponse(
            content={"error": f"An error occurred: {str(e)}"}, 
            status_code=500
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
